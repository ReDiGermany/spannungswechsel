{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import math\n",
    "import numpy as np\n",
    "import json \n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, './car')\n",
    "from nearest_neighbour import nearest_neighbour\n",
    "sys.path.insert(0, './car/detector')\n",
    "import aux\n",
    "import server\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import cv2\n",
    "import pyzed.sl as sl\n",
    "\n",
    "from threading import Lock, Thread\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, './yolov5')\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import check_img_size, non_max_suppression\n",
    "from utils.torch_utils import select_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globale Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lock = Lock()\n",
    "run_signal = False\n",
    "exit_signal = False\n",
    "\n",
    "pylons = [\"blue\",\"green\",\"orange\",\"pink\",\"yellow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bizzi Waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bizzi = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Cone Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colors in BGR\n",
    "Cache = {\n",
    "    \"blue\": {\n",
    "        \"classId\": 0,\n",
    "        \"color\": (255,0,0),\n",
    "        \"items\": {}\n",
    "    },\n",
    "    \"green\": {\n",
    "        \"classId\": 1,\n",
    "        \"color\": (0,255,0),\n",
    "        \"items\": {}\n",
    "    },\n",
    "    \"red\": {\n",
    "        \"classId\": 2,\n",
    "        \"color\": (0,0,255),\n",
    "        \"items\": {}\n",
    "    },\n",
    "    \"pink\": {\n",
    "        \"classId\": 3,\n",
    "        \"color\": (255,0,255),\n",
    "        \"items\": {}\n",
    "    },\n",
    "    \"yellow\": {\n",
    "        \"classId\": 4,\n",
    "        \"color\": (0,255,255),\n",
    "        \"items\": {}\n",
    "    },\n",
    "    \"self\": {\n",
    "        \"classId\": [],\n",
    "        \"color\": (0,0,0),\n",
    "        \"items\": {\n",
    "            \"0\":{\n",
    "                \"translation\":{\n",
    "                    \"x\": 0,\n",
    "                    \"y\": 0,\n",
    "                    \"z\": 0,\n",
    "                },\n",
    "                \"orientation\": {\n",
    "                    \"x\": 0,\n",
    "                    \"y\": 0,\n",
    "                    \"z\": 0,\n",
    "                    \"w\": 0,\n",
    "                },\n",
    "                \"timestamp\": 0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "server.setCache(Cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cam():\n",
    "    zed = sl.Camera()\n",
    "    input_type = sl.InputType()\n",
    "    if opt[\"svo\"] is not None:\n",
    "        input_type.set_from_svo_file(opt[\"svo\"])\n",
    "\n",
    "    # Create a InitParameters object and set configuration parameters\n",
    "    init_params = sl.InitParameters(input_t=input_type, svo_real_time_mode=True)\n",
    "    init_params.camera_resolution = sl.RESOLUTION.HD1080\n",
    "    init_params.coordinate_units = sl.UNIT.CENTIMETER\n",
    "    init_params.coordinate_system = sl.COORDINATE_SYSTEM.LEFT_HANDED_Y_UP\n",
    "    # init_params.depth_mode = sl.DEPTH_MODE.ULTRA  # QUALITY\n",
    "    init_params.depth_mode = sl.DEPTH_MODE.QUALITY #PERFORMANCE  # QUALITY\n",
    "    # init_params.depth_maximum_distance = 20\n",
    "    status = zed.open(init_params)\n",
    "    return zed, status, init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_camera_settings(zed):\n",
    "    print(\"BRIGHTNESS: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.BRIGHTNESS))) # 0 - 8\n",
    "    print(\"CONTRAST: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.CONTRAST))) # 0 - 8\n",
    "    print(\"HUE: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.HUE))) # 0 - 11\n",
    "    print(\"SATURATION: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.SATURATION))) # 0 - 8\n",
    "    print(\"SHARPNESS: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.SHARPNESS))) # 0 - 8\n",
    "    print(\"GAMMA: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.GAMMA))) # 1 - 9\n",
    "    print(\"GAIN: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.GAIN))) # 0 - 100\n",
    "    print(\"EXPOSURE: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.EXPOSURE))) # 0 - 100\n",
    "    print(\"AEC_AGC: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.AEC_AGC))) # True | False\n",
    "    print(\"AEC_AGC_ROI: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.AEC_AGC_ROI))) # True | False\n",
    "    print(\"WHITEBALANCE_TEMPERATURE: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.WHITEBALANCE_TEMPERATURE))) # 2800 - 6500 (100+)\n",
    "    print(\"WHITEBALANCE_AUTO: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.WHITEBALANCE_AUTO))) # True | False\n",
    "    print(\"LED_STATUS: {0}\".format(zed.get_camera_settings(sl.VIDEO_SETTINGS.LED_STATUS))) # 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_tracking(zed):\n",
    "    \n",
    "    # If the camera is static, uncomment the following line to have better performances and boxes sticked to the ground.\n",
    "    positional_tracking_parameters = sl.PositionalTrackingParameters()\n",
    "    # positional_tracking_parameters.set_as_static = True\n",
    "    # positional_tracking_parameters.initial_world_transform = True\n",
    "\n",
    "    initial_position = sl.Transform()\n",
    "    initial_translation = sl.Translation()\n",
    "    # initial_translation.init_vector(0,18,-75)\n",
    "    initial_position.set_translation(initial_translation)\n",
    "    positional_tracking_parameters.set_initial_world_transform(initial_position)\n",
    "\n",
    "    zed.enable_positional_tracking(positional_tracking_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_object_detection(zed):\n",
    "    \n",
    "    obj_param = sl.ObjectDetectionParameters()\n",
    "    obj_param.detection_model = sl.DETECTION_MODEL.CUSTOM_BOX_OBJECTS\n",
    "    # obj_param.enable_tracking = True\n",
    "    # obj_param.enable_mask_output = True\n",
    "    zed.enable_object_detection(obj_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_position(zed):\n",
    "    # Get the pose of the camera relative to the world frame\n",
    "    state = zed.get_position(cam_w_pose, sl.REFERENCE_FRAME.WORLD)\n",
    "    # Display translation and timestamp\n",
    "    py_translation = sl.Translation()\n",
    "    tx = round(cam_w_pose.get_translation(py_translation).get()[0], 3)\n",
    "    ty = round(cam_w_pose.get_translation(py_translation).get()[1], 3)\n",
    "    tz = round(cam_w_pose.get_translation(py_translation).get()[2], 3)\n",
    "    # print(\"Translation: tx: {0}, ty:  {1}, tz:  {2}, timestamp: {3}\".format(tx, ty, tz, cam_w_pose.timestamp.get_seconds()))\n",
    "    #Display orientation quaternion\n",
    "    py_orientation = sl.Orientation()\n",
    "    ox = round(cam_w_pose.get_orientation(py_orientation).get()[0], 3)\n",
    "    oy = round(cam_w_pose.get_orientation(py_orientation).get()[1], 3)\n",
    "    oz = round(cam_w_pose.get_orientation(py_orientation).get()[2], 3)\n",
    "    ow = round(cam_w_pose.get_orientation(py_orientation).get()[3], 3)\n",
    "\n",
    "    ex = round(cam_w_pose.get_euler_angles()[0],3)\n",
    "    ey = round(cam_w_pose.get_euler_angles()[1],3)\n",
    "    ez = round(cam_w_pose.get_euler_angles()[2],3)\n",
    "\n",
    "    vx = round(cam_w_pose.get_rotation_vector()[0],3)\n",
    "    vy = round(cam_w_pose.get_rotation_vector()[1],3)\n",
    "    vz = round(cam_w_pose.get_rotation_vector()[2],3)\n",
    "\n",
    "    # print(\"Translation: tx: {0}, ty:  {1}, tz:  {2}, timestamp: {3} | Orientation: ox: {4}, oy:  {5}, oz: {6}, ow: {7}\".format(tx, ty, tz, cam_w_pose.timestamp.get_seconds(),ox, oy, oz, ow))\n",
    "    # roll_x, pitch_y, yaw_z = euler_from_quaternion(ox,oy,oz,ow)\n",
    "    # (x, y, z, w):\n",
    "    Cache[\"self\"][\"items\"][\"0\"] = {\n",
    "        \"translation\":{\n",
    "            \"x\": tx,\n",
    "            \"y\": ty,\n",
    "            \"z\": tz,\n",
    "        },\n",
    "        \"orientation\": {\n",
    "            \"x\": ox,\n",
    "            \"y\": oy,\n",
    "            \"z\": oz,\n",
    "            \"w\": ow,\n",
    "        },\n",
    "        \"euler\": {\n",
    "            \"x\": ex,\n",
    "            \"y\": ey,\n",
    "            \"z\": ez,\n",
    "        },\n",
    "        \"rvect\": {\n",
    "            \"x\": vx,\n",
    "            \"y\": vy,\n",
    "            \"z\": vz,\n",
    "        },\n",
    "        \"timestamp\": cam_w_pose.timestamp.get_seconds()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(img_size,weights,device):\n",
    "    device = select_device()\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "    imgsz = img_size\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, device,False)  # load FP32\n",
    "    bizzi = False\n",
    "    stride = int(model.stride.max())  # model stride\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Run inference\n",
    "    if device.type != 'cpu':\n",
    "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image():\n",
    "    img, ratio, pad = aux.img_preprocess(image_net, device, half, imgsz)\n",
    "    pred = model(img)[0]\n",
    "    det = non_max_suppression(pred, conf_thres, iou_thres)\n",
    "    detections = aux.detections_to_custom_box(det, img, image_net)\n",
    "    zed.ingest_custom_box_objects(detections)\n",
    "    zed.retrieve_objects(objects, obj_runtime_param)\n",
    "    # if objects.is_new :\n",
    "    obj_array = objects.object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_and_process():\n",
    "    update_position(zed)\n",
    "    zed.retrieve_image(image_left_tmp, sl.VIEW.LEFT)\n",
    "    image_net = image_left_tmp.get_data()\n",
    "\n",
    "    process_image()\n",
    "\n",
    "    tempTime = str(datetime.utcnow().strftime('%H:%M:%S.%f')[:-3])[0:8]\n",
    "    if timeName != tempTime:\n",
    "        print(\"FPS: {0}\".format(str(timeNum)))\n",
    "        timeNum = 0\n",
    "        timeName = tempTime\n",
    "    timeNum = timeNum + 1\n",
    "\n",
    "    blue_pylons = []\n",
    "    red_pylons = []\n",
    "    if len(obj_array) > 0:\n",
    "        for obj in obj_array:\n",
    "            if not math.isnan(obj.position[0]):\n",
    "                if obj.tracking_state==sl.OBJECT_TRACKING_STATE.OK:\n",
    "\n",
    "                    color = (0,0,0)\n",
    "\n",
    "                    def position_to_object(pos):\n",
    "                        return {\"x\":pos[0],\"y\":pos[1],\"z\":pos[2]}\n",
    "\n",
    "                    def compare_position_and_update(old,new,limit=0.5):\n",
    "                        a = np.array((old[\"x\"],old[\"y\"],old[\"z\"]))\n",
    "                        b = np.array((new[\"x\"],new[\"y\"],new[\"z\"]))\n",
    "                        dist = np.linalg.norm(a-b)\n",
    "                        return old if dist > limit else new\n",
    "\n",
    "                    key = \"\"\n",
    "\n",
    "                    if(obj.raw_label == Cache[\"blue\"][\"classId\"]):\n",
    "                        key = \"blue\"\n",
    "                    elif(obj.raw_label == Cache[\"green\"][\"classId\"]):\n",
    "                        key = \"green\"\n",
    "                    elif(obj.raw_label == Cache[\"red\"][\"classId\"]):\n",
    "                        key = \"red\"\n",
    "                    elif(obj.raw_label == Cache[\"pink\"][\"classId\"]):\n",
    "                        key = \"pink\"\n",
    "                    elif(obj.raw_label == Cache[\"yellow\"][\"classId\"]):\n",
    "                        key = \"yellow\"\n",
    "                    else:\n",
    "                        print(\"Found pylon out of identity\")\n",
    "                        return\n",
    "\n",
    "\n",
    "                    color = Cache[key][\"color\"]\n",
    "                    if obj.id in Cache[key][\"items\"]:\n",
    "                        Cache[key][\"items\"][obj.id] = compare_position_and_update(\n",
    "                            Cache[key][\"items\"][obj.id],\n",
    "                            position_to_object(obj.position)\n",
    "                        )\n",
    "                    else:\n",
    "                        Cache[key][\"items\"][obj.id] = position_to_object(obj.position)\n",
    "\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    org = (int(obj.bounding_box_2d[0][0]),int(obj.bounding_box_2d[0][1]))\n",
    "                    fontScale = .5\n",
    "                    thickness = 1\n",
    "                    image_net = cv2.putText(image_net, \"(id: {2} | class: {3}) {0} x {1}\".format(\n",
    "                        round(obj.position[0]-30),\n",
    "                        round(obj.position[2]),\n",
    "                        obj.id,\n",
    "                        key\n",
    "                    ), org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                    # print(\"draw\")\n",
    "                    cv2.line(image_net, (int(obj.bounding_box_2d[0][0]),int(obj.bounding_box_2d[0][1])),(int(obj.bounding_box_2d[1][0]),int(obj.bounding_box_2d[1][1])), color, 1) \n",
    "                    cv2.line(image_net, (int(obj.bounding_box_2d[1][0]),int(obj.bounding_box_2d[1][1])),(int(obj.bounding_box_2d[2][0]),int(obj.bounding_box_2d[2][1])), color, 1) \n",
    "                    cv2.line(image_net, (int(obj.bounding_box_2d[2][0]),int(obj.bounding_box_2d[2][1])),(int(obj.bounding_box_2d[3][0]),int(obj.bounding_box_2d[3][1])), color, 1) \n",
    "                    cv2.line(image_net, (int(obj.bounding_box_2d[3][0]),int(obj.bounding_box_2d[3][1])),(int(obj.bounding_box_2d[0][0]),int(obj.bounding_box_2d[0][1])), color, 1) \n",
    "\n",
    "        # print(\"show\")\n",
    "\n",
    "        temp_pylons = []\n",
    "\n",
    "        def copy_item(item,i,cls):\n",
    "            return {\"x\":item[\"x\"],\"y\":item[\"y\"],\"color\":cls,\"id\":str(i)}\n",
    "\n",
    "        for item in Cache[\"blue\"][\"items\"]:\n",
    "            temp_pylons.append(copy_item(Cache[\"blue\"][\"items\"][item],item,\"blue\"))\n",
    "\n",
    "        for item in Cache[\"green\"][\"items\"]:\n",
    "            temp_pylons.append(copy_item(Cache[\"green\"][\"items\"][item],item,\"blue\"))\n",
    "\n",
    "        for item in Cache[\"red\"][\"items\"]:\n",
    "            temp_pylons.append(copy_item(Cache[\"red\"][\"items\"][item],item,\"red\"))\n",
    "\n",
    "        for item in Cache[\"pink\"][\"items\"]:\n",
    "            temp_pylons.append(copy_item(Cache[\"pink\"][\"items\"][item],item,\"red\"))\n",
    "\n",
    "        # print(temp_pylons)\n",
    "\n",
    "        route = None\n",
    "        neighbours = None\n",
    "        curve = None\n",
    "        pylons = None\n",
    "        blue_curved = None\n",
    "        red_curved = None\n",
    "\n",
    "        if(len(temp_pylons)):\n",
    "            route,neighbours,curve,pylons,blue_curved,red_curved = nearest_neighbour(temp_pylons,False)\n",
    "\n",
    "        # json_object = json.dumps(Cache)\n",
    "        json_object = json.dumps({\n",
    "            \"neighbours\": neighbours,\n",
    "            \"route\": route,\n",
    "            \"curve\": curve,\n",
    "            \"pylons\": pylons,\n",
    "            \"blueCurved\": blue_curved,\n",
    "            \"redCurved\": red_curved,\n",
    "        })\n",
    "        server.setImage(image_net[:,:,:3])\n",
    "        now = datetime.now()\n",
    "        if secCache != now.second:\n",
    "            secCache  = now.second\n",
    "            server.sendWebsocketMessage(\"left-eye:\"+str(aux.image_to_base64(image_net[:,:,:3])))\n",
    "        # server.sendWebsocketMessage(\"chart:\"+str(aux.image_to_base64(image)))\n",
    "        server.setPositions(json_object)\n",
    "        # server.sendWebsocketMessage(\"pylons:\"+json_object)\n",
    "        # else:\n",
    "        #     plotPylons([], [],image_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_thread(weights, img_size, conf_thres=0.2, iou_thres=0.45):\n",
    "    global image_net, exit_signal, run_signal, detections\n",
    "    print(\"Initializing Camera...\")\n",
    "    \n",
    "   \n",
    "    zed, status, init_params = init_cam()           # Init Cam\n",
    "    runtime_params = sl.RuntimeParameters()         # Getting Runtime Parameters\n",
    "    #debug_camera_settings(zed)                      # Printing all camera settings to console\n",
    "    server.setZed(zed,sl)                           # Setting Zed inside the Server to change settings later via API\n",
    "\n",
    "    # Making sure Camera status is ok\n",
    "    if status != sl.ERROR_CODE.SUCCESS:\n",
    "        print(repr(status))\n",
    "        exit()\n",
    "\n",
    "    # Preparing variable\n",
    "    image_left_tmp = sl.Mat()\n",
    "    timeName = \"\"\n",
    "    timeNum = 0\n",
    "    secCache = 0\n",
    "\n",
    "    print(\"Initialized Camera\")\n",
    "\n",
    "    enable_tracking(zed)\n",
    "    enable_object_detection(zed)\n",
    "    \n",
    "    objects = sl.Objects()\n",
    "    obj_runtime_param = sl.ObjectDetectionRuntimeParameters()\n",
    "    # obj_runtime_param.detection_confidence_threshold = 25\n",
    "\n",
    "    # Display\n",
    "    cam_w_pose = sl.Pose()\n",
    "\n",
    "    print(\"Intializing Network...\")\n",
    "    init_network(img_size,weights,device)\n",
    "    \n",
    "    while not exit_signal:\n",
    "        if zed.grab(runtime_params) == sl.ERROR_CODE.SUCCESS:\n",
    "            get_image_and_process()\n",
    "        else:\n",
    "            print(\"failed\")\n",
    "    print(\"done\")\n",
    "\n",
    "    zed.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Camera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-7 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6855MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMERA STREAM FAILED TO START\n",
      "Initialized Camera\n",
      "Intializing Network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_57104/2470244653.py\", line 35, in plt_thread\n",
      "  File \"/tmp/ipykernel_57104/2839698965.py\", line 7, in init_network\n",
      "NameError: name 'weights' is not defined\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    \"weights\": \"best.pt\",\n",
    "    \"svo\": None,\n",
    "    \"img_size\": 416,\n",
    "    \"conf_thres\": 0.4,\n",
    "}\n",
    "\n",
    "plot_thread = Thread(target=plt_thread, kwargs={\n",
    "    'weights': opt[\"weights\"],\n",
    "    'img_size': opt[\"img_size\"],\n",
    "    \"conf_thres\": opt[\"conf_thres\"]\n",
    "})\n",
    "plot_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_signal = True\n",
    "plot_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using wlan0's ip: 192.168.0.19\n",
      "Web Server started @ http://192.168.0.19:8080\n",
      "WebSocket Server started @ http://192.168.0.19:8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 0\n",
      "FPS: 2\n",
      "FPS: 4\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 1\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 1\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 2\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 1\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 2\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n",
      "FPS: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartServers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spannungswechsel/./car/detector/server.py:272\u001b[0m, in \u001b[0;36mstartServers\u001b[0;34m()\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m \u001b[43mwebThread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m wsThread\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    274\u001b[0m webServer\u001b[38;5;241m.\u001b[39mserver_close()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[0;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "server.startServers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.stopServer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
